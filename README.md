# fast-local-llm-coder

## install

- llama-coder for vscode : https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder
- llama-coder : https://github.com/ex3ndr/llama-coder

## setting
```
http://localhost:11434
```
